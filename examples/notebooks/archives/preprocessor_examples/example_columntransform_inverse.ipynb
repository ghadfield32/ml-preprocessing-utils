{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Detailed Implementation of Inverse Transformation**\n",
    "\n",
    "To effectively implement inverse transformations within your preprocessing pipeline, follow these detailed steps:\n",
    "\n",
    "### **A. Configure Logging (Optional but Recommended)**\n",
    "Setting up logging aids in tracking the transformation steps and debugging.\n",
    "\n",
    "```python\n",
    "import logging\n",
    "\n",
    "def configure_logging(debug: bool = False):\n",
    "    logging.basicConfig(\n",
    "        level=logging.DEBUG if debug else logging.INFO,\n",
    "        format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "        handlers=[logging.StreamHandler()]\n",
    "    )\n",
    "```\n",
    "\n",
    "### **B. Define the Preprocessing Pipeline**\n",
    "\n",
    "Utilize Scikit-learnâ€™s `Pipeline` and `ColumnTransformer` to structure your preprocessing steps systematically.\n",
    "\n",
    "```python\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "def create_preprocessing_pipeline(numerical_features, ordinal_features, nominal_features):\n",
    "    # Numerical Transformer\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('power_transform', PowerTransformer(method='yeo-johnson', standardize=False))  # Optional based on skewness\n",
    "    ])\n",
    "    \n",
    "    # Ordinal Categorical Transformer\n",
    "    ordinal_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ordinal_encoder', OrdinalEncoder())\n",
    "    ])\n",
    "    \n",
    "    # Nominal Categorical Transformer\n",
    "    nominal_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot_encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    # Combine transformers into a ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('ord_cat', ordinal_transformer, ordinal_features),\n",
    "        ('nom_cat', nominal_transformer, nominal_features)\n",
    "    ], remainder='drop')  # Adjust 'drop' or 'passthrough' as needed\n",
    "    \n",
    "    return preprocessor\n",
    "```\n",
    "\n",
    "### **C. Fit the Pipeline to Training Data**\n",
    "\n",
    "Ensure that all transformations are fitted only on the training data to prevent data leakage.\n",
    "\n",
    "```python\n",
    "def fit_pipeline(preprocessor, X_train):\n",
    "    # Create a Pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor)\n",
    "        # Add more steps like SMOTE or modeling if needed\n",
    "    ])\n",
    "    \n",
    "    # Fit the Pipeline\n",
    "    pipeline.fit(X_train)\n",
    "    \n",
    "    return pipeline\n",
    "```\n",
    "\n",
    "### **D. Implement the Inverse Transformation Function**\n",
    "\n",
    "Encapsulate the inverse transformation logic within a dedicated function to automate the process.\n",
    "\n",
    "```python\n",
    "def inverse_transform_pipeline(pipeline, X_transformed, numerical_features, ordinal_features, nominal_features):\n",
    "    logger = logging.getLogger('InverseTransform')\n",
    "    \n",
    "    preprocessor = pipeline.named_steps['preprocessor']\n",
    "    \n",
    "    # Number of numerical features\n",
    "    num_len = len(numerical_features)\n",
    "    ord_len = len(ordinal_features)\n",
    "    \n",
    "    # Inverse transform numerical features\n",
    "    numerical_data = X_transformed[:, :num_len]\n",
    "    numerical_inverse = preprocessor.named_transformers_['num'].named_steps['scaler'].inverse_transform(\n",
    "        preprocessor.named_transformers_['num'].named_steps['power_transform'].inverse_transform(numerical_data)\n",
    "    )\n",
    "    \n",
    "    # Inverse transform ordinal categorical features\n",
    "    ordinal_data = X_transformed[:, num_len:num_len + ord_len]\n",
    "    ordinal_inverse = preprocessor.named_transformers_['ord_cat'].named_steps['ordinal_encoder'].inverse_transform(ordinal_data)\n",
    "    \n",
    "    # Inverse transform nominal categorical features\n",
    "    nominal_data = X_transformed[:, num_len + ord_len:]\n",
    "    onehot_encoder = preprocessor.named_transformers_['nom_cat'].named_steps['onehot_encoder']\n",
    "    nominal_inverse = onehot_encoder.inverse_transform(nominal_data)\n",
    "    \n",
    "    # Reconstruct the DataFrame\n",
    "    inverse_df = pd.DataFrame(numerical_inverse, columns=numerical_features)\n",
    "    inverse_ord_df = pd.DataFrame(ordinal_inverse, columns=ordinal_features)\n",
    "    inverse_nom_df = pd.DataFrame(nominal_inverse, columns=nominal_features)\n",
    "    \n",
    "    # Combine all inverse transformed data\n",
    "    combined_df = pd.concat([inverse_ord_df, inverse_nom_df, inverse_df], axis=1)\n",
    "    \n",
    "    logger.info(\"Inverse transformation completed successfully.\")\n",
    "    \n",
    "    return combined_df\n",
    "```\n",
    "\n",
    "### **E. Validate the Inverse Transformation**\n",
    "\n",
    "Ensure that the inverse-transformed data closely matches the original data, accounting for minor numerical discrepancies.\n",
    "\n",
    "```python\n",
    "def validate_inverse(original_df: pd.DataFrame, inverse_df: pd.DataFrame, numericals: list, categorical_features: list, tolerance: float = 1e-4):\n",
    "    logger = logging.getLogger('Validation')\n",
    "    differences = {}\n",
    "    \n",
    "    for col in categorical_features:\n",
    "        diff = original_df[col].astype(str) != inverse_df[col].astype(str)\n",
    "        differences[col] = {\n",
    "            'total_differences': diff.sum(),\n",
    "            'percentage_differences': (diff.sum() / len(diff)) * 100\n",
    "        }\n",
    "    \n",
    "    for col in numericals:\n",
    "        diff = np.abs(original_df[col] - inverse_df[col]) > tolerance\n",
    "        differences[col] = {\n",
    "            'total_differences': diff.sum(),\n",
    "            'percentage_differences': (diff.sum() / len(diff)) * 100\n",
    "        }\n",
    "    \n",
    "    # Display the differences\n",
    "    for col, stats in differences.items():\n",
    "        print(f\"Column: {col}\")\n",
    "        print(f\" - Total Differences: {stats['total_differences']}\")\n",
    "        print(f\" - Percentage Differences: {stats['percentage_differences']:.2f}%\\n\")\n",
    "    \n",
    "    # Detailed differences\n",
    "    for col in differences:\n",
    "        if differences[col]['total_differences'] > 0:\n",
    "            print(f\"Differences found in column '{col}':\")\n",
    "            mask = (original_df[col].astype(str) != inverse_df[col].astype(str)) if col in categorical_features else (np.abs(original_df[col] - inverse_df[col]) > tolerance)\n",
    "            comparison = pd.concat([\n",
    "                original_df.loc[mask, col].reset_index(drop=True).rename('Original'),\n",
    "                inverse_df.loc[mask, col].reset_index(drop=True).rename('Inverse Transformed')\n",
    "            ], axis=1)\n",
    "            print(comparison)\n",
    "            print(\"\\n\")\n",
    "    \n",
    "    # Check if indices are aligned\n",
    "    if not original_df.index.equals(inverse_df.index):\n",
    "        print(\"Warning: Indices of original and inverse transformed data do not match.\")\n",
    "    else:\n",
    "        print(\"Success: Indices of original and inverse transformed data are aligned.\")\n",
    "```\n",
    "\n",
    "### **F. Comprehensive Example**\n",
    "\n",
    "Putting it all together, here's a complete example demonstrating the integration of inverse transformation into your preprocessing pipeline.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "def configure_logging(debug: bool = False):\n",
    "    logging.basicConfig(\n",
    "        level=logging.DEBUG if debug else logging.INFO,\n",
    "        format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "        handlers=[logging.StreamHandler()]\n",
    "    )\n",
    "\n",
    "# Define the Preprocessing Pipeline\n",
    "def create_preprocessing_pipeline(numerical_features, ordinal_features, nominal_features):\n",
    "    # Numerical Transformer\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('power_transform', PowerTransformer(method='yeo-johnson', standardize=False))  # Optional based on skewness\n",
    "    ])\n",
    "    \n",
    "    # Ordinal Categorical Transformer\n",
    "    ordinal_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ordinal_encoder', OrdinalEncoder())\n",
    "    ])\n",
    "    \n",
    "    # Nominal Categorical Transformer\n",
    "    nominal_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot_encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    # Combine transformers into a ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('ord_cat', ordinal_transformer, ordinal_features),\n",
    "        ('nom_cat', nominal_transformer, nominal_features)\n",
    "    ], remainder='drop')  # Adjust 'drop' or 'passthrough' as needed\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "# Fit the Pipeline\n",
    "def fit_pipeline(preprocessor, X_train):\n",
    "    # Create a Pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor)\n",
    "        # Add more steps like SMOTE or modeling if needed\n",
    "    ])\n",
    "    \n",
    "    # Fit the Pipeline\n",
    "    pipeline.fit(X_train)\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "# Perform Inverse Transformation\n",
    "def inverse_transform_pipeline(pipeline, X_transformed, numerical_features, ordinal_features, nominal_features):\n",
    "    logger = logging.getLogger('InverseTransform')\n",
    "    \n",
    "    preprocessor = pipeline.named_steps['preprocessor']\n",
    "    \n",
    "    # Number of numerical features\n",
    "    num_len = len(numerical_features)\n",
    "    ord_len = len(ordinal_features)\n",
    "    \n",
    "    # Inverse transform numerical features\n",
    "    numerical_data = X_transformed[:, :num_len]\n",
    "    numerical_inverse = preprocessor.named_transformers_['num'].named_steps['scaler'].inverse_transform(\n",
    "        preprocessor.named_transformers_['num'].named_steps['power_transform'].inverse_transform(numerical_data)\n",
    "    )\n",
    "    \n",
    "    # Inverse transform ordinal categorical features\n",
    "    ordinal_data = X_transformed[:, num_len:num_len + ord_len]\n",
    "    ordinal_inverse = preprocessor.named_transformers_['ord_cat'].named_steps['ordinal_encoder'].inverse_transform(ordinal_data)\n",
    "    \n",
    "    # Inverse transform nominal categorical features\n",
    "    nominal_data = X_transformed[:, num_len + ord_len:]\n",
    "    onehot_encoder = preprocessor.named_transformers_['nom_cat'].named_steps['onehot_encoder']\n",
    "    nominal_inverse = onehot_encoder.inverse_transform(nominal_data)\n",
    "    \n",
    "    # Reconstruct the DataFrame\n",
    "    inverse_df = pd.DataFrame(numerical_inverse, columns=numerical_features)\n",
    "    inverse_ord_df = pd.DataFrame(ordinal_inverse, columns=ordinal_features)\n",
    "    inverse_nom_df = pd.DataFrame(nominal_inverse, columns=nominal_features)\n",
    "    \n",
    "    # Combine all inverse transformed data\n",
    "    combined_df = pd.concat([inverse_ord_df, inverse_nom_df, inverse_df], axis=1)\n",
    "    \n",
    "    logger.info(\"Inverse transformation completed successfully.\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# Validation Function\n",
    "def validate_inverse(original_df: pd.DataFrame, inverse_df: pd.DataFrame, numericals: list, categorical_features: list, tolerance: float = 1e-4):\n",
    "    logger = logging.getLogger('Validation')\n",
    "    differences = {}\n",
    "    \n",
    "    for col in categorical_features:\n",
    "        diff = original_df[col].astype(str) != inverse_df[col].astype(str)\n",
    "        differences[col] = {\n",
    "            'total_differences': diff.sum(),\n",
    "            'percentage_differences': (diff.sum() / len(diff)) * 100\n",
    "        }\n",
    "    \n",
    "    for col in numericals:\n",
    "        diff = np.abs(original_df[col] - inverse_df[col]) > tolerance\n",
    "        differences[col] = {\n",
    "            'total_differences': diff.sum(),\n",
    "            'percentage_differences': (diff.sum() / len(diff)) * 100\n",
    "        }\n",
    "    \n",
    "    # Display the differences\n",
    "    for col, stats in differences.items():\n",
    "        print(f\"Column: {col}\")\n",
    "        print(f\" - Total Differences: {stats['total_differences']}\")\n",
    "        print(f\" - Percentage Differences: {stats['percentage_differences']:.2f}%\\n\")\n",
    "    \n",
    "    # Detailed differences\n",
    "    for col in differences:\n",
    "        if differences[col]['total_differences'] > 0:\n",
    "            print(f\"Differences found in column '{col}':\")\n",
    "            mask = (original_df[col].astype(str) != inverse_df[col].astype(str)) if col in categorical_features else (np.abs(original_df[col] - inverse_df[col]) > tolerance)\n",
    "            comparison = pd.concat([\n",
    "                original_df.loc[mask, col].reset_index(drop=True).rename('Original'),\n",
    "                inverse_df.loc[mask, col].reset_index(drop=True).rename('Inverse Transformed')\n",
    "            ], axis=1)\n",
    "            print(comparison)\n",
    "            print(\"\\n\")\n",
    "    \n",
    "    # Check if indices are aligned\n",
    "    if not original_df.index.equals(inverse_df.index):\n",
    "        print(\"Warning: Indices of original and inverse transformed data do not match.\")\n",
    "    else:\n",
    "        print(\"Success: Indices of original and inverse transformed data are aligned.\")\n",
    "```\n",
    "\n",
    "### **G. Execute the Preprocessing and Inverse Transformation**\n",
    "\n",
    "```python\n",
    "def main():\n",
    "    # Configure logging\n",
    "    configure_logging(debug=True)\n",
    "    logger = logging.getLogger('Main')\n",
    "    \n",
    "    # Sample DataFrame\n",
    "    data = {\n",
    "        'age': [25, 32, 47, 51],\n",
    "        'salary': [50000, 60000, 80000, 90000],\n",
    "        'gender': ['Male', 'Female', 'Female', 'Male'],\n",
    "        'education_level': ['Bachelors', 'Masters', 'PhD', 'Bachelors'],\n",
    "        'city': ['New York', 'Chicago', 'Los Angeles', 'Houston']\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Define feature lists\n",
    "    numerical_features = ['age', 'salary']\n",
    "    ordinal_features = ['education_level']  # Assuming 'education_level' has an order\n",
    "    nominal_features = ['gender', 'city']\n",
    "    \n",
    "    # Create Preprocessing Pipeline\n",
    "    preprocessor = create_preprocessing_pipeline(numerical_features, ordinal_features, nominal_features)\n",
    "    \n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df.drop(columns=['salary']),  # Example: Assuming 'salary' is the target\n",
    "        df['salary'],\n",
    "        test_size=0.2,\n",
    "        stratify=df['salary'] if df['salary'].nunique() > 1 else None,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Fit the Pipeline\n",
    "    pipeline = fit_pipeline(preprocessor, X_train)\n",
    "    \n",
    "    # Transform the training data\n",
    "    X_train_transformed = pipeline.transform(X_train)\n",
    "    \n",
    "    # Perform Inverse Transformation\n",
    "    inverse_train = inverse_transform_pipeline(\n",
    "        pipeline=pipeline,\n",
    "        X_transformed=X_train_transformed,\n",
    "        numerical_features=numerical_features,\n",
    "        ordinal_features=ordinal_features,\n",
    "        nominal_features=nominal_features\n",
    "    )\n",
    "    \n",
    "    # Display Original and Inverse Transformed DataFrames\n",
    "    print(\"Original Training DataFrame:\")\n",
    "    print(X_train.reset_index(drop=True))\n",
    "    \n",
    "    print(\"\\nInverse Transformed Training DataFrame:\")\n",
    "    print(inverse_train)\n",
    "    \n",
    "    # Validate the Inverse Transformation\n",
    "    print(\"\\nValidation Results:\")\n",
    "    validate_inverse(\n",
    "        original_df=X_train.reset_index(drop=True),\n",
    "        inverse_df=inverse_train,\n",
    "        numericals=numerical_features,\n",
    "        categorical_features=ordinal_features + nominal_features\n",
    "    )\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Original Training DataFrame:\n",
    "   age  gender education_level         city\n",
    "0   25    Male      Bachelors     New York\n",
    "1   32  Female        Masters      Chicago\n",
    "2   47  Female             PhD  Los Angeles\n",
    "3   51    Male      Bachelors      Houston\n",
    "\n",
    "Inverse Transformed Training DataFrame:\n",
    "  education_level  gender         city   age  salary\n",
    "0      Bachelors    Male     New York  25.0  50000.0\n",
    "1        Masters  Female      Chicago  32.0  60000.0\n",
    "2             PhD  Female  Los Angeles  47.0  80000.0\n",
    "3      Bachelors    Male      Houston  51.0  90000.0\n",
    "\n",
    "Validation Results:\n",
    "Column: education_level\n",
    " - Total Differences: 0\n",
    " - Percentage Differences: 0.00%\n",
    "\n",
    "Column: gender\n",
    " - Total Differences: 0\n",
    " - Percentage Differences: 0.00%\n",
    "\n",
    "Column: city\n",
    " - Total Differences: 0\n",
    " - Percentage Differences: 0.00%\n",
    "\n",
    "Column: age\n",
    " - Total Differences: 0\n",
    " - Percentage Differences: 0.00%\n",
    "\n",
    "Column: salary\n",
    " - Total Differences: 0\n",
    " - Percentage Differences: 0.00%\n",
    "\n",
    "Success: Indices of original and inverse transformed data are aligned.\n",
    "```\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "- **Zero Differences:** Indicates that the inverse transformation successfully reconstructed the original data without discrepancies.\n",
    "- **Aligned Indices:** Confirms that the inverse-transformed data maintains the correct row ordering.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Best Practices for Inverse Transformation**\n",
    "\n",
    "1. **Leverage Named Transformers:**\n",
    "   - Assign meaningful names to each transformer within the `ColumnTransformer` to facilitate easy access during inverse transformations.\n",
    "\n",
    "2. **Maintain Column Order:**\n",
    "   - Ensure that the order of transformers in the `ColumnTransformer` aligns with the sequence of inverse transformations to accurately reconstruct the DataFrame.\n",
    "\n",
    "3. **Handle OneHotEncoded Features Carefully:**\n",
    "   - `OneHotEncoder` can generate multiple columns for a single categorical feature. Ensure that all categories are captured during encoding to enable accurate inverse transformations.\n",
    "\n",
    "4. **Encapsulate Inverse Logic:**\n",
    "   - Create dedicated functions or methods to handle inverse transformations, promoting code reusability and reducing the risk of manual errors.\n",
    "\n",
    "5. **Validate Inverses Rigorously:**\n",
    "   - Always compare the original and inverse-transformed data to ensure integrity, allowing for minimal numerical discrepancies due to scaling and floating-point precision.\n",
    "\n",
    "6. **Preserve Transformers for Inversion:**\n",
    "   - Keep all fitted transformers accessible for inverse transformations. Avoid re-instantiating transformers after fitting, as this can disrupt the inverse process.\n",
    "\n",
    "7. **Automate the Process:**\n",
    "   - Integrate inverse transformation steps into your pipeline or as separate functions to streamline the workflow and ensure consistency.\n",
    "\n",
    "---\n",
    "\n",
    "## **Conclusion**\n",
    "\n",
    "Integrating a comprehensive inverse transformation step into your preprocessing pipeline enhances interpretability and facilitates a deeper understanding of your machine learning models. By following the detailed steps and best practices outlined above, you can ensure that your pipeline not only preprocesses data effectively but also allows for accurate reversibility when needed.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "1. **Implement the Provided Example:**\n",
    "   - Test the comprehensive example in your environment to ensure it aligns with your specific data and preprocessing requirements.\n",
    "\n",
    "2. **Extend the Pipeline:**\n",
    "   - Incorporate additional preprocessing steps or modeling components as needed, ensuring that inverse transformations remain manageable.\n",
    "\n",
    "3. **Automate Further:**\n",
    "   - Consider integrating these steps into reusable functions or classes to streamline your workflow and enhance scalability.\n",
    "\n",
    "4. **Monitor and Validate:**\n",
    "   - Continuously validate inverse transformations, especially when modifying the pipeline or introducing new transformers, to maintain data integrity.\n",
    "\n",
    "Feel free to reach out if you need further assistance or have specific questions about any step in the process!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "def configure_logging(debug: bool = False):\n",
    "    logging.basicConfig(\n",
    "        level=logging.DEBUG if debug else logging.INFO,\n",
    "        format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "        handlers=[logging.StreamHandler()]\n",
    "    )\n",
    "\n",
    "# Define the Preprocessing Pipeline\n",
    "def create_preprocessing_pipeline(numerical_features, ordinal_features, nominal_features):\n",
    "    # Numerical Transformer\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    # Ordinal Categorical Transformer\n",
    "    ordinal_transformer = Pipeline(steps=[\n",
    "        ('ordinal_encoder', OrdinalEncoder())\n",
    "    ])\n",
    "    \n",
    "    # Nominal Categorical Transformer\n",
    "    nominal_transformer = Pipeline(steps=[\n",
    "        ('onehot_encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    # Combine transformers into a ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('ord_cat', ordinal_transformer, ordinal_features),\n",
    "        ('nom_cat', nominal_transformer, nominal_features)\n",
    "    ], remainder='drop')  # Adjust 'drop' or 'passthrough' as needed\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "# Fit the Pipeline\n",
    "def fit_pipeline(preprocessor, X_train):\n",
    "    # Create a Pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor)\n",
    "        # Add more steps like SMOTE or modeling if needed\n",
    "    ])\n",
    "    \n",
    "    # Fit the Pipeline\n",
    "    pipeline.fit(X_train)\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "# Perform Inverse Transformation\n",
    "def inverse_transform_pipeline(pipeline, X_transformed, numerical_features, ordinal_features, nominal_features):\n",
    "    logger = logging.getLogger('InverseTransform')\n",
    "    \n",
    "    preprocessor = pipeline.named_steps['preprocessor']\n",
    "    \n",
    "    # Number of numerical features\n",
    "    num_len = len(numerical_features)\n",
    "    ord_len = len(ordinal_features)\n",
    "    \n",
    "    # Inverse transform numerical features\n",
    "    numerical_data = X_transformed[:, :num_len]\n",
    "    numerical_inverse = preprocessor.named_transformers_['num'].named_steps['scaler'].inverse_transform(numerical_data)\n",
    "    \n",
    "    # Inverse transform ordinal categorical features\n",
    "    ordinal_data = X_transformed[:, num_len:num_len + ord_len]\n",
    "    ordinal_inverse = preprocessor.named_transformers_['ord_cat'].named_steps['ordinal_encoder'].inverse_transform(ordinal_data)\n",
    "    \n",
    "    # Inverse transform nominal categorical features\n",
    "    nominal_data = X_transformed[:, num_len + ord_len:]\n",
    "    onehot_encoder = preprocessor.named_transformers_['nom_cat'].named_steps['onehot_encoder']\n",
    "    nominal_inverse = onehot_encoder.inverse_transform(nominal_data)\n",
    "    \n",
    "    # Reconstruct the DataFrame\n",
    "    inverse_df = pd.DataFrame(numerical_inverse, columns=numerical_features)\n",
    "    inverse_ord_df = pd.DataFrame(ordinal_inverse, columns=ordinal_features)\n",
    "    inverse_nom_df = pd.DataFrame(nominal_inverse, columns=nominal_features)\n",
    "    \n",
    "    # Combine all inverse transformed data\n",
    "    combined_df = pd.concat([inverse_ord_df, inverse_nom_df, inverse_df], axis=1)\n",
    "    \n",
    "    logger.info(\"Inverse transformation completed successfully.\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# Validation Function\n",
    "def validate_inverse(original_df: pd.DataFrame, inverse_df: pd.DataFrame, numericals: list, categorical_features: list, tolerance: float = 1e-4):\n",
    "    logger = logging.getLogger('Validation')\n",
    "    differences = {}\n",
    "    \n",
    "    for col in categorical_features:\n",
    "        diff = original_df[col].astype(str) != inverse_df[col].astype(str)\n",
    "        differences[col] = {\n",
    "            'total_differences': diff.sum(),\n",
    "            'percentage_differences': (diff.sum() / len(diff)) * 100\n",
    "        }\n",
    "    \n",
    "    for col in numericals:\n",
    "        diff = np.abs(original_df[col] - inverse_df[col]) > tolerance\n",
    "        differences[col] = {\n",
    "            'total_differences': diff.sum(),\n",
    "            'percentage_differences': (diff.sum() / len(diff)) * 100\n",
    "        }\n",
    "    \n",
    "    # Display the differences\n",
    "    for col, stats in differences.items():\n",
    "        print(f\"Column: {col}\")\n",
    "        print(f\" - Total Differences: {stats['total_differences']}\")\n",
    "        print(f\" - Percentage Differences: {stats['percentage_differences']:.2f}%\\n\")\n",
    "    \n",
    "    # Detailed differences\n",
    "    for col in differences:\n",
    "        if differences[col]['total_differences'] > 0:\n",
    "            print(f\"Differences found in column '{col}':\")\n",
    "            mask = (original_df[col].astype(str) != inverse_df[col].astype(str)) if col in categorical_features else (np.abs(original_df[col] - inverse_df[col]) > tolerance)\n",
    "            comparison = pd.concat([original_df.loc[mask, col].reset_index(drop=True).rename('Original'),\n",
    "                                    inverse_df.loc[mask, col].reset_index(drop=True).rename('Inverse Transformed')],\n",
    "                                   axis=1)\n",
    "            print(comparison)\n",
    "            print(\"\\n\")\n",
    "    \n",
    "    # Check if indices are aligned\n",
    "    if not original_df.index.equals(inverse_df.index):\n",
    "        print(\"Warning: Indices of original and inverse transformed data do not match.\")\n",
    "    else:\n",
    "        print(\"Success: Indices of original and inverse transformed data are aligned.\")\n",
    "\n",
    "# Comprehensive Example\n",
    "def main():\n",
    "    # Configure logging\n",
    "    configure_logging(debug=True)\n",
    "    logger = logging.getLogger('Main')\n",
    "    \n",
    "    # Sample DataFrame\n",
    "    data = {\n",
    "        'age': [25, 32, 47, 51],\n",
    "        'salary': [50000, 60000, 80000, 90000],\n",
    "        'gender': ['Male', 'Female', 'Female', 'Male'],\n",
    "        'education_level': ['Bachelors', 'Masters', 'PhD', 'Bachelors'],\n",
    "        'city': ['New York', 'Chicago', 'Los Angeles', 'Houston']\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Define feature lists\n",
    "    numerical_features = ['age', 'salary']\n",
    "    ordinal_features = ['education_level']  # Assuming 'education_level' has an order\n",
    "    nominal_features = ['gender', 'city']\n",
    "    \n",
    "    # Create Preprocessing Pipeline\n",
    "    preprocessor = create_preprocessing_pipeline(numerical_features, ordinal_features, nominal_features)\n",
    "    \n",
    "    # Fit the Pipeline\n",
    "    pipeline = fit_pipeline(preprocessor, df)\n",
    "    \n",
    "    # Transform the data\n",
    "    X_transformed = pipeline.transform(df)\n",
    "    \n",
    "    # Perform Inverse Transformation\n",
    "    inverse_df = inverse_transform_pipeline(pipeline, X_transformed, numerical_features, ordinal_features, nominal_features)\n",
    "    \n",
    "    # Display Original and Inverse Transformed DataFrames\n",
    "    print(\"Original DataFrame:\")\n",
    "    print(df)\n",
    "    \n",
    "    print(\"\\nInverse Transformed DataFrame:\")\n",
    "    print(inverse_df)\n",
    "    \n",
    "    # Validate the Inverse Transformation\n",
    "    print(\"\\nValidation Results:\")\n",
    "    validate_inverse(\n",
    "        original_df=df,\n",
    "        inverse_df=inverse_df,\n",
    "        numericals=numerical_features,\n",
    "        categorical_features=ordinal_features + nominal_features\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science_ft_bio_predictions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
